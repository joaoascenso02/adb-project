{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BDA - Phase 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MySQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine, text\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df = pd.read_csv(\n",
    "    filepath_or_buffer='../data/clean-data/relational/host.csv',\n",
    "    dtype={\n",
    "        'id': 'int64',\n",
    "        'url': 'string',\n",
    "        'name': 'string',\n",
    "        'about': 'string',\n",
    "        'is_superhost': 'bool',\n",
    "        'thumbnail_url': 'string',\n",
    "        'picture_url': 'string',\n",
    "        'verifications': 'string',\n",
    "        'location': 'string',\n",
    "        'neighbourhood': 'string'\n",
    "    }\n",
    ")\n",
    "\n",
    "host_statistics_df = pd.read_csv(\n",
    "    filepath_or_buffer='../data/clean-data/relational/host_statistics.csv',\n",
    "    dtype={\n",
    "        \"id\": \"int32\",\n",
    "        \"host_id\": \"int32\",\n",
    "        \"response_time\": \"string\",\n",
    "        \"response_rate\": \"float32\",\n",
    "        \"acceptance_rate\": \"float32\",\n",
    "        \"listings_count\": \"int16\",\n",
    "        \"total_listings_count\": \"int16\",\n",
    "        \"calculated_host_listings_count\": \"int16\",\n",
    "        \"calculated_host_listings_count_entire_homes\": \"int16\",\n",
    "        \"calculated_host_listings_count_private_rooms\": \"int16\",\n",
    "        \"calculated_host_listings_count_shared_rooms\": \"int16\"\n",
    "    },\n",
    "    parse_dates=[\"since\"]\n",
    ")\n",
    "\n",
    "listings_df = pd.read_csv(\n",
    "    filepath_or_buffer='../data/clean-data/relational/listings.csv', \n",
    "    dtype={\n",
    "        \"id\": \"int32\",\n",
    "        \"listing_url\": \"string\",\n",
    "        \"name\": \"string\",\n",
    "        \"description\": \"string\",\n",
    "        \"neighborhood_overview\": \"string\",\n",
    "        \"picture_url\": \"string\",\n",
    "        \"host_id\": \"int32\",\n",
    "        \"neighbourhood\": \"string\",\n",
    "        \"latitude\": \"float32\",\n",
    "        \"longitude\": \"float32\",\n",
    "        \"property_type\": \"string\",\n",
    "        \"room_type\": \"string\",\n",
    "        \"accommodates\": \"int16\",\n",
    "        \"bathrooms\": \"float32\",\n",
    "        \"bathrooms_text\": \"string\",\n",
    "        \"bedrooms\": \"float32\",\n",
    "        \"beds\": \"float32\",\n",
    "        \"amenities\": \"string\",\n",
    "        \"base_price\": \"float32\",\n",
    "        \"minimum_nights\": \"int16\",\n",
    "        \"maximum_nights\": \"int16\",\n",
    "        \"has_availability\": \"bool\",\n",
    "        \"instant_bookable\": \"bool\"\n",
    "    },\n",
    "    parse_dates=[\"last_scraped\"]\n",
    ")\n",
    "\n",
    "calendar_df = pd.read_csv(\n",
    "    filepath_or_buffer='../data/clean-data/relational/calendar.csv',\n",
    "    dtype={\n",
    "        \"id\": \"int32\",\n",
    "        \"listing_id\": \"int32\",\n",
    "        \"available\": \"bool\",\n",
    "        \"price\": \"float32\"\n",
    "    },\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "\n",
    "reviews_df = pd.read_csv(\n",
    "    filepath_or_buffer='../data/clean-data/relational/reviews.csv',\n",
    "    dtype={\n",
    "        \"id\": \"int32\",\n",
    "        \"listing_id\": \"int32\",\n",
    "        \"reviewer_id\": \"int32\",\n",
    "        \"reviewer_name\": \"string\",\n",
    "        \"comments\": \"string\"\n",
    "    },\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "\n",
    "availability_statistics_df = pd.read_csv(\n",
    "    filepath_or_buffer='../data/clean-data/relational/availability_statistics.csv',\n",
    "    dtype={\n",
    "        \"id\": \"int32\",\n",
    "        \"listing_id\": \"int32\",\n",
    "        \"minimum_minimum_nights\": \"int16\",\n",
    "        \"maximum_minimum_nights\": \"int16\",\n",
    "        \"minimum_maximum_nights\": \"int16\",\n",
    "        \"maximum_maximum_nights\": \"int16\",\n",
    "        \"minimum_nights_avg_ntm\": \"float32\",\n",
    "        \"maximum_nights_avg_ntm\": \"float32\",\n",
    "        \"availability_30\": \"int16\",\n",
    "        \"availability_60\": \"int16\",\n",
    "        \"availability_90\": \"int16\",\n",
    "        \"availability_365\": \"int16\"\n",
    "    }\n",
    ")\n",
    "\n",
    "reviews_statistics_df = pd.read_csv(\n",
    "    filepath_or_buffer='../data/clean-data/relational/reviews_statistics.csv',\n",
    "    dtype={\n",
    "        \"id\": \"int32\",\n",
    "        \"listing_id\": \"int32\",\n",
    "        \"number_of_reviews\": \"int16\",\n",
    "        \"number_of_reviews_ltm\": \"int16\",\n",
    "        \"number_of_reviews_l30d\": \"int16\",\n",
    "        \"review_scores_rating\": \"float32\",\n",
    "        \"review_scores_accuracy\": \"float32\",\n",
    "        \"review_scores_cleanliness\": \"float32\",\n",
    "        \"review_scores_checkin\": \"float32\",\n",
    "        \"review_scores_communication\": \"float32\",\n",
    "        \"review_scores_location\": \"float32\",\n",
    "        \"review_scores_value\": \"float32\",\n",
    "        \"reviews_per_month\": \"float32\"\n",
    "    },\n",
    "    parse_dates=[\"first_review\", \"last_review\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Create the DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed: -- Create the HOST table...\n",
      "Executed: -- Create the HOST_STATISTICS table...\n",
      "Executed: -- Create the LISTINGS table...\n",
      "Executed: -- Create the CALENDAR table...\n",
      "Executed: -- Create the REVIEWS table...\n",
      "Executed: -- Create the AVAILABILITY_STATISTICS table...\n",
      "Executed: -- Create the REVIEWS_STATISTICS table...\n",
      "Error with statement: CREATE TABLE RESULTS (...\n",
      "1050 (42S01): Table 'results' already exists\n",
      "Schema successfully loaded into the database!\n",
      "Table 'HOST_STATISTICS' data inserted successfully!\n",
      "Table 'CALENDAR' data inserted successfully!\n",
      "Table 'REVIEWS' data inserted successfully!\n",
      "Table 'AVAILABILITY_STATISTICS' data inserted successfully!\n",
      "Table 'REVIEWS_STATISTICS' data inserted successfully!\n",
      "Table 'LISTINGS' data inserted successfully!\n",
      "Table 'HOST' data inserted successfully!\n",
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "username = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database_name = 'Project_DB'\n",
    "schema_file = '../schemas/db_schema.sql'\n",
    "\n",
    "def load_sql_schema(cursor, schema_file):\n",
    "    try:\n",
    "        with open(schema_file, 'r') as f:\n",
    "            sql_script = f.read()\n",
    "        statements = sql_script.split(';')\n",
    "        for statement in statements:\n",
    "            if statement.strip():\n",
    "                try:\n",
    "                    cursor.execute(statement)\n",
    "                    print(f\"Executed: {statement.strip().splitlines()[0]}...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with statement: {statement.strip().splitlines()[0]}...\\n{e}\")\n",
    "        print(\"Schema successfully loaded into the database!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Schema file not found: {schema_file}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading schema file: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_dataframes_to_mysql(engine, dataframes):\n",
    "    try:\n",
    "        for table_name, dataframe in dataframes.items():\n",
    "            dataframe.to_sql(table_name, con=engine, if_exists='replace', index=False, method='multi')\n",
    "            print(f\"Table '{table_name}' data inserted successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataframes: {e}\")\n",
    "        raise\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    with mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=username,\n",
    "        password=password\n",
    "    ) as mydb:\n",
    "        with mydb.cursor() as cursor:\n",
    "            cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {database_name}\")\n",
    "            cursor.execute(f\"USE {database_name}\")\n",
    "            load_sql_schema(cursor, schema_file)\n",
    "        mydb.commit()\n",
    "\n",
    "    db_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "    engine = create_engine(db_url)\n",
    "\n",
    "    # dataframes = {\n",
    "    #     \"host_statistics\": host_statistics_df,\n",
    "    #     \"calendar\": calendar_df,\n",
    "    #     \"reviews\": reviews_df,\n",
    "    #     \"availability_statistics\": availability_statistics_df,\n",
    "    #     \"reviews_statistics\": reviews_statistics_df,\n",
    "    #     \"listings\": listings_df,\n",
    "    #     \"host\": host_df,\n",
    "    # }\n",
    "\n",
    "    dataframes = {\n",
    "        \"HOST_STATISTICS\": host_statistics_df,\n",
    "        \"CALENDAR\": calendar_df,\n",
    "        \"REVIEWS\": reviews_df,\n",
    "        \"AVAILABILITY_STATISTICS\": availability_statistics_df,\n",
    "        \"REVIEWS_STATISTICS\": reviews_statistics_df,\n",
    "        \"LISTINGS\": listings_df,\n",
    "        \"HOST\": host_df,\n",
    "    }\n",
    "\n",
    "    load_dataframes_to_mysql(engine, dataframes)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    print(\"Process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Queries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Queries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 results found in 0.0017 seconds\n"
     ]
    }
   ],
   "source": [
    "username = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database_name = 'Project_DB'\n",
    "\n",
    "simple_query = \"\"\"\n",
    "SELECT *\n",
    "FROM listings\n",
    "WHERE has_availability = TRUE\n",
    "AND bedrooms = 2\n",
    "AND base_price < 100;\n",
    "\"\"\"\n",
    "\n",
    "db_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        start_time = time.time()\n",
    "        result = connection.execute(text(simple_query))\n",
    "        results = result.fetchall()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"{len(results)} results found in {end_time - start_time:.4f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while executing the query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 results found in 0.0025 seconds\n"
     ]
    }
   ],
   "source": [
    "username = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database_name = 'Project_DB'\n",
    "\n",
    "simple_query = \"\"\"\n",
    "WITH unique_host_statistics AS (\n",
    "    SELECT host_id, MAX(listings_count) AS listings_count\n",
    "    FROM host_statistics\n",
    "    WHERE listings_count > 1\n",
    "    GROUP BY host_id\n",
    ")\n",
    "SELECT h.id, h.location\n",
    "FROM host h\n",
    "JOIN unique_host_statistics uhs ON h.id = uhs.host_id\n",
    "WHERE h.location = 'Albany, NY';\n",
    "\"\"\"\n",
    "\n",
    "db_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        start_time = time.time()\n",
    "        result = connection.execute(text(simple_query))\n",
    "        results = result.fetchall()\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"{len(results)} results found in {end_time - start_time:.4f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while executing the query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Complex Queries:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complex Query 1: Hosts em New York**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_query = \"\"\"\n",
    "WITH average_prices AS (\n",
    "    SELECT \n",
    "        l.host_id,\n",
    "        AVG(l.base_price) AS avg_price\n",
    "    FROM listings l\n",
    "    WHERE l.has_availability = TRUE\n",
    "    GROUP BY l.host_id\n",
    "),\n",
    "host_with_high_listings AS (\n",
    "    SELECT \n",
    "        l.host_id,\n",
    "        COUNT(DISTINCT l.id) AS listings_count\n",
    "    FROM listings l\n",
    "    GROUP BY l.host_id\n",
    "    HAVING COUNT(DISTINCT l.id) > 5\n",
    ")\n",
    "SELECT \n",
    "    h.id AS host_id,\n",
    "    h.name AS host_name,\n",
    "    h.location AS host_location,\n",
    "    apl.avg_price AS average_price,\n",
    "    hhl.listings_count AS total_listings\n",
    "FROM host h\n",
    "JOIN average_prices apl ON h.id = apl.host_id\n",
    "JOIN host_with_high_listings hhl ON h.id = hhl.host_id\n",
    "WHERE apl.avg_price < 150\n",
    "AND h.location = 'New York, NY'\n",
    "ORDER BY apl.avg_price ASC;\n",
    "\"\"\"\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO RESULTS (host_id, host_name, host_location, average_price, total_listings)\n",
    "VALUES (:host_id, :host_name, :host_location, :average_price, :total_listings)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 records inserted into RESULTS.\n",
      "6 results found and inserted in 0.0066 seconds\n"
     ]
    }
   ],
   "source": [
    "# without index\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        start_time = time.time()\n",
    "\n",
    "        result = connection.execute(text(complex_query))\n",
    "        results = result.fetchall()\n",
    "\n",
    "        if results:\n",
    "            for row in results:\n",
    "                connection.execute(\n",
    "                    text(insert_query),\n",
    "                    {\n",
    "                        \"host_id\": row[0],\n",
    "                        \"host_name\": row[1],\n",
    "                        \"host_location\": row[2],\n",
    "                        \"average_price\": row[3],\n",
    "                        \"total_listings\": row[4],\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            connection.commit()\n",
    "            print(f\"{len(results)} records inserted into RESULTS.\")\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"{len(results)} results found and inserted in {end_time - start_time:.4f} seconds\")\n",
    "        else:\n",
    "            print(\"No results to insert.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing indexes\n",
      "No indexes in LISTINGS\n",
      "No indexes in HOST_STATISTICS\n",
      "No indexes in HOST\n",
      "\n",
      "Creating simple indexes\n",
      "Simple Indexes created successfully.\n",
      "\n",
      "Creating compound indexes\n",
      "Compound Indexes created successfully\n",
      "\n",
      "Executing the query\n",
      "6 records inserted into RESULTS.\n",
      "6 results found and inserted in 0.0031 seconds\n",
      "\n",
      "Removing created indexes\n",
      "Indexes removed successfully.\n"
     ]
    }
   ],
   "source": [
    "# with indexes and insert functionality\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Existing indexes\")\n",
    "        listings_indexes = connection.execute(text(\"SHOW INDEX FROM LISTINGS\"))\n",
    "        host_statistics_indexes = connection.execute(text(\"SHOW INDEX FROM HOST_STATISTICS\"))\n",
    "        host_indexes = connection.execute(text(\"SHOW INDEX FROM HOST\"))\n",
    "        \n",
    "        if listings_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in LISTINGS:\")\n",
    "            for row in listings_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in LISTINGS\")\n",
    "\n",
    "        if host_statistics_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in HOST_STATISTICS:\")\n",
    "            for row in host_statistics_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in HOST_STATISTICS\")\n",
    "\n",
    "        if host_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in HOST:\")\n",
    "            for row in host_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in HOST\")\n",
    "\n",
    "        print(\"\\nCreating simple indexes\")\n",
    "        connection.execute(text(\"CREATE INDEX idx_listings_host_id ON LISTINGS (host_id);\")) \n",
    "        connection.execute(text(\"CREATE INDEX idx_host_statistics_host_id ON HOST_STATISTICS (host_id);\")) \n",
    "        connection.execute(text(\"CREATE INDEX idx_host_location ON HOST (location(255));\")) \n",
    "        print(\"Simple Indexes created successfully.\")\n",
    "\n",
    "        print(\"\\nCreating compound indexes\")\n",
    "        connection.execute(text(\"CREATE INDEX idx_listings_availability_price ON LISTINGS (has_availability, base_price);\")) \n",
    "        connection.execute(text(\"CREATE INDEX idx_host_statistics_listings_count ON HOST_STATISTICS (listings_count);\"))\n",
    "        print(\"Compound Indexes created successfully\")\n",
    "        \n",
    "        print(\"\\nExecuting the query\")\n",
    "        start_time = time.time()\n",
    "        result = connection.execute(text(complex_query))\n",
    "        results = result.fetchall()\n",
    "\n",
    "        if results:\n",
    "            for row in results:\n",
    "                connection.execute(\n",
    "                    text(insert_query),\n",
    "                    {\n",
    "                        \"host_id\": row[0],\n",
    "                        \"host_name\": row[1],\n",
    "                        \"host_location\": row[2],\n",
    "                        \"average_price\": row[3],\n",
    "                        \"total_listings\": row[4],\n",
    "                    }\n",
    "                )\n",
    "            print(f\"{len(results)} records inserted into RESULTS.\")\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"{len(results)} results found and inserted in {end_time - start_time:.4f} seconds\")\n",
    "        else:\n",
    "            print(\"No results to insert.\")\n",
    "\n",
    "\n",
    "        print(\"\\nRemoving created indexes\")\n",
    "        connection.execute(text(\"DROP INDEX idx_listings_host_id ON LISTINGS;\"))\n",
    "        connection.execute(text(\"DROP INDEX idx_host_statistics_host_id ON HOST_STATISTICS;\"))\n",
    "        connection.execute(text(\"DROP INDEX idx_host_location ON HOST;\"))\n",
    "        connection.execute(text(\"DROP INDEX idx_listings_availability_price ON LISTINGS;\"))\n",
    "        connection.execute(text(\"DROP INDEX idx_host_statistics_listings_count ON HOST_STATISTICS;\"))\n",
    "        print(\"Indexes removed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while creating the indexes or executing the query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the RESULTS table:\n",
      "(109, 42708277, 'Rodney', 'New York, NY', 102.167, 8)\n",
      "(110, 42708277, 'Rodney', 'New York, NY', 102.167, 8)\n",
      "(111, 42708277, 'Rodney', 'New York, NY', 102.167, 8)\n",
      "(112, 42708277, 'Rodney', 'New York, NY', 102.167, 8)\n",
      "(113, 42708277, 'Rodney', 'New York, NY', 102.167, 8)\n",
      "(114, 42708277, 'Rodney', 'New York, NY', 102.167, 8)\n",
      "(115, 110453341, 'Alexis', 'New York, NY', 103.0, 7)\n",
      "(116, 385664127, 'Dillon', 'New York, NY', 104.5, 7)\n",
      "(117, 385664127, 'Dillon', 'New York, NY', 104.5, 7)\n",
      "The RESULTS table contains 9 rows.\n"
     ]
    }
   ],
   "source": [
    "# visualize insert in RESULTS table\n",
    "\n",
    "username = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database_name = 'Project_DB'\n",
    "\n",
    "db_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        query_all = text(\"SELECT * FROM RESULTS\")\n",
    "        result_all = connection.execute(query_all)\n",
    "        rows = result_all.fetchall()\n",
    "        \n",
    "        print(\"Contents of the RESULTS table:\")\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "        \n",
    "        query_count = text(\"SELECT COUNT(*) FROM RESULTS;\")\n",
    "        result_count = connection.execute(query_count)\n",
    "        count = result_count.scalar()  # single value result\n",
    "        \n",
    "        print(f\"The RESULTS table contains {count} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows deleted from the RESULTS table. Total rows affected: 9\n"
     ]
    }
   ],
   "source": [
    "# clear RESULTS table\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        query_clear = text(\"DELETE FROM RESULTS\")\n",
    "        result_clear = connection.execute(query_clear)\n",
    "    \n",
    "        connection.commit()    \n",
    "        print(f\"All rows deleted from the RESULTS table. Total rows affected: {result_clear.rowcount}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while clearing the RESULTS table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complex query 2: Atualização de preços de Listings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_price_update_query = \"\"\"\n",
    "WITH high_reviewed_listings AS (\n",
    "    SELECT \n",
    "        rs.listing_id\n",
    "    FROM REVIEWS_STATISTICS rs\n",
    "    WHERE rs.review_scores_rating > 4.5\n",
    "      AND rs.number_of_reviews > 100\n",
    "),\n",
    "active_hosts AS (\n",
    "    SELECT \n",
    "        hs.host_id,\n",
    "        MAX(hs.total_listings_count) AS max_listings_count,\n",
    "        SUM(l.has_availability) AS available_listings\n",
    "    FROM HOST_STATISTICS hs\n",
    "    JOIN LISTINGS l ON hs.host_id = l.host_id\n",
    "    GROUP BY hs.host_id\n",
    ")\n",
    "UPDATE LISTINGS l\n",
    "JOIN high_reviewed_listings hl ON l.id = hl.listing_id\n",
    "JOIN active_hosts ah ON l.host_id = ah.host_id\n",
    "JOIN HOST h ON l.host_id = h.id\n",
    "SET l.base_price = l.base_price * 1.1 \n",
    "WHERE ah.max_listings_count > 5\n",
    "    AND ah.available_listings > 3\n",
    "    AND l.base_price < 300\n",
    "    AND h.location = 'Albany, NY'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 results changed in 0.2389 seconds\n"
     ]
    }
   ],
   "source": [
    "# without index\n",
    "\n",
    "username = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database_name = 'Project_DB'\n",
    "\n",
    "db_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        start_time = time.time()\n",
    "        result = connection.execute(text(base_price_update_query))\n",
    "        connection.commit()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        affected_rows = result.rowcount\n",
    "        print(f\"{affected_rows} results changed in {end_time - start_time:.4f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while executing the query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing indexes\n",
      "No indexes in LISTINGS\n",
      "No indexes in REVIEWS_STATISTICS\n",
      "\n",
      "Creating indexes\n",
      "Indexes created successfully.\n",
      "Indexes in LISTINGS:\n",
      "('LISTINGS', 1, 'id_index', 1, 'id', 'A', 371, None, None, 'YES', 'BTREE', '', '', 'YES', None)\n",
      "('LISTINGS', 1, 'list_index', 1, 'base_price', 'A', 170, None, None, 'YES', 'BTREE', '', '', 'YES', None)\n",
      "('LISTINGS', 1, 'list_index', 2, 'has_availability', 'A', 174, None, None, 'YES', 'BTREE', '', '', 'YES', None)\n",
      "Indexes in REVIEWS_STATISTICS:\n",
      "('REVIEWS_STATISTICS', 1, 'RS_index', 1, 'listing_id', 'A', 426, None, None, 'YES', 'BTREE', '', '', 'YES', None)\n",
      "('REVIEWS_STATISTICS', 1, 'Where_index', 1, 'number_of_reviews', 'A', 140, None, None, 'YES', 'BTREE', '', '', 'YES', None)\n",
      "('REVIEWS_STATISTICS', 1, 'Where_index', 2, 'review_scores_rating', 'A', 280, None, None, 'YES', 'BTREE', '', '', 'YES', None)\n",
      "\n",
      "Executing the query\n",
      "24 results changed in 0.0187 seconds\n",
      "\n",
      "Removing created indexes\n",
      "Indexes removed successfully.\n"
     ]
    }
   ],
   "source": [
    "# with indexes\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Existing indexes\")\n",
    "        listings_indexes = connection.execute(text(\"SHOW INDEX FROM LISTINGS\"))\n",
    "        reviews_statistics_indexes = connection.execute(text(\"SHOW INDEX FROM REVIEWS_STATISTICS\"))\n",
    "\n",
    "        if listings_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in LISTINGS:\")\n",
    "            for row in listings_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in LISTINGS\")\n",
    "\n",
    "        if reviews_statistics_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in REVIEWS_STATISTICS:\")\n",
    "            for row in reviews_statistics_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in REVIEWS_STATISTICS\")\n",
    "\n",
    "        # add indexes\n",
    "        print(\"\\nCreating indexes\")\n",
    "        connection.execute(text(\"CREATE INDEX id_index ON LISTINGS (id);\"))\n",
    "        connection.execute(text(\"CREATE INDEX RS_index ON REVIEWS_STATISTICS (listing_id);\"))\n",
    "        connection.execute(text(\"CREATE INDEX list_index ON LISTINGS (base_price, has_availability);\"))\n",
    "        connection.execute(text(\"CREATE INDEX Where_index ON REVIEWS_STATISTICS (number_of_reviews, review_scores_rating);\"))\n",
    "        print(\"Indexes created successfully.\")\n",
    "\n",
    "        listings_indexes = connection.execute(text(\"SHOW INDEX FROM LISTINGS\"))\n",
    "        reviews_statistics_indexes = connection.execute(text(\"SHOW INDEX FROM REVIEWS_STATISTICS\"))\n",
    "\n",
    "        print(\"Indexes in LISTINGS:\")\n",
    "        for row in listings_indexes:\n",
    "            print(row)\n",
    "\n",
    "        print(\"Indexes in REVIEWS_STATISTICS:\")\n",
    "        for row in reviews_statistics_indexes:\n",
    "            print(row)\n",
    "\n",
    "        # execute the query\n",
    "        print(\"\\nExecuting the query\")\n",
    "        start_time = time.time()\n",
    "        result = connection.execute(text(base_price_update_query))\n",
    "        connection.commit()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        affected_rows = result.rowcount\n",
    "        print(f\"{affected_rows} results changed in {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "        # remove indexes\n",
    "        print(\"\\nRemoving created indexes\")\n",
    "        connection.execute(text(\"DROP INDEX id_index ON LISTINGS;\"))\n",
    "        connection.execute(text(\"DROP INDEX RS_index ON REVIEWS_STATISTICS;\"))\n",
    "        connection.execute(text(\"DROP INDEX list_index ON LISTINGS;\"))\n",
    "        connection.execute(text(\"DROP INDEX Where_index ON REVIEWS_STATISTICS;\"))\n",
    "        print(\"Indexes removed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4 Data Model Aleterations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully in 0.0111 seconds:\n",
      "ALTER TABLE LISTINGS ...\n",
      "Query executed successfully in 0.0781 seconds:\n",
      "UPDATE LISTINGS l...\n",
      "Schema modifications and data updates completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import time\n",
    "\n",
    "username = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database_name = 'Project_DB'\n",
    "\n",
    "db_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "schema_and_update_queries = [\n",
    "    #  columns in LISTINGS table \n",
    "    \"\"\"\n",
    "    ALTER TABLE LISTINGS \n",
    "    ADD COLUMN review_scores_rating FLOAT DEFAULT 0.0,\n",
    "    ADD COLUMN number_of_reviews INT DEFAULT 0;\n",
    "    \"\"\",\n",
    "\n",
    "    # update LISTINGS with columns from REVIEWS_STATISTICS table\n",
    "    \"\"\"\n",
    "    UPDATE LISTINGS l\n",
    "    JOIN REVIEWS_STATISTICS rs ON l.id = rs.listing_id\n",
    "    SET l.review_scores_rating = rs.review_scores_rating,\n",
    "        l.number_of_reviews = rs.number_of_reviews;\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        for query in schema_and_update_queries:\n",
    "            start_time = time.time()\n",
    "            connection.execute(text(query))\n",
    "            connection.commit()\n",
    "            end_time = time.time()\n",
    "            print(f\"Query executed successfully in {end_time - start_time:.4f} seconds:\\n{query.strip().splitlines()[0]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while executing the schema changes: {e}\")\n",
    "finally:\n",
    "    print(\"Schema modifications and data updates completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Complex Queries after model update:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complex Query 1: Hosts em New York**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_query = \"\"\"\n",
    "WITH average_prices AS (\n",
    "    SELECT \n",
    "        l.host_id,\n",
    "        AVG(l.base_price) AS avg_price\n",
    "    FROM listings l\n",
    "    WHERE l.has_availability = TRUE\n",
    "    GROUP BY l.host_id\n",
    "),\n",
    "host_with_high_listings AS (\n",
    "    SELECT \n",
    "        l.host_id,\n",
    "        COUNT(DISTINCT l.id) AS listings_count\n",
    "    FROM listings l\n",
    "    GROUP BY l.host_id\n",
    "    HAVING COUNT(DISTINCT l.id) > 5\n",
    ")\n",
    "SELECT \n",
    "    h.id AS host_id,\n",
    "    h.name AS host_name,\n",
    "    h.location AS host_location,\n",
    "    apl.avg_price AS average_price,\n",
    "    hhl.listings_count AS total_listings\n",
    "FROM host h\n",
    "JOIN average_prices apl ON h.id = apl.host_id\n",
    "JOIN host_with_high_listings hhl ON h.id = hhl.host_id\n",
    "WHERE apl.avg_price < 150\n",
    "AND h.location = 'New York, NY'\n",
    "ORDER BY apl.avg_price ASC;\n",
    "\"\"\"\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO RESULTS (host_id, host_name, host_location, average_price, total_listings)\n",
    "VALUES (:host_id, :host_name, :host_location, :average_price, :total_listings)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 records inserted into RESULTS.\n",
      "6 results found and inserted in 0.0053 seconds\n"
     ]
    }
   ],
   "source": [
    "# without index\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        start_time = time.time()\n",
    "\n",
    "        result = connection.execute(text(complex_query))\n",
    "        results = result.fetchall()\n",
    "\n",
    "        if results:\n",
    "            for row in results:\n",
    "                connection.execute(\n",
    "                    text(insert_query),\n",
    "                    {\n",
    "                        \"host_id\": row[0],\n",
    "                        \"host_name\": row[1],\n",
    "                        \"host_location\": row[2],\n",
    "                        \"average_price\": row[3],\n",
    "                        \"total_listings\": row[4],\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            connection.commit()\n",
    "            print(f\"{len(results)} records inserted into RESULTS.\")\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"{len(results)} results found and inserted in {end_time - start_time:.4f} seconds\")\n",
    "        else:\n",
    "            print(\"No results to insert.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing indexes\n",
      "No indexes in LISTINGS\n",
      "No indexes in HOST_STATISTICS\n",
      "No indexes in HOST\n",
      "\n",
      "Creating simple indexes\n",
      "Simple Indexes created successfully.\n",
      "\n",
      "Creating compound indexes\n",
      "Compound Indexes created successfully\n",
      "\n",
      "Executing the query\n",
      "6 records inserted into RESULTS.\n",
      "6 results found and inserted in 0.0030 seconds\n",
      "\n",
      "Removing created indexes\n",
      "Indexes removed successfully.\n"
     ]
    }
   ],
   "source": [
    "# with indexes and insert functionality\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Existing indexes\")\n",
    "        listings_indexes = connection.execute(text(\"SHOW INDEX FROM LISTINGS\"))\n",
    "        host_statistics_indexes = connection.execute(text(\"SHOW INDEX FROM HOST_STATISTICS\"))\n",
    "        host_indexes = connection.execute(text(\"SHOW INDEX FROM HOST\"))\n",
    "        \n",
    "        if listings_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in LISTINGS:\")\n",
    "            for row in listings_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in LISTINGS\")\n",
    "\n",
    "        if host_statistics_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in HOST_STATISTICS:\")\n",
    "            for row in host_statistics_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in HOST_STATISTICS\")\n",
    "\n",
    "        if host_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in HOST:\")\n",
    "            for row in host_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in HOST\")\n",
    "\n",
    "        print(\"\\nCreating simple indexes\")\n",
    "        connection.execute(text(\"CREATE INDEX idx_listings_host_id ON LISTINGS (host_id);\")) \n",
    "        connection.execute(text(\"CREATE INDEX idx_host_statistics_host_id ON HOST_STATISTICS (host_id);\")) \n",
    "        connection.execute(text(\"CREATE INDEX idx_host_location ON HOST (location(255));\")) \n",
    "        print(\"Simple Indexes created successfully.\")\n",
    "\n",
    "        print(\"\\nCreating compound indexes\")\n",
    "        connection.execute(text(\"CREATE INDEX idx_listings_availability_price ON LISTINGS (has_availability, base_price);\")) \n",
    "        connection.execute(text(\"CREATE INDEX idx_host_statistics_listings_count ON HOST_STATISTICS (listings_count);\"))\n",
    "        print(\"Compound Indexes created successfully\")\n",
    "        \n",
    "        print(\"\\nExecuting the query\")\n",
    "        start_time = time.time()\n",
    "        result = connection.execute(text(complex_query))\n",
    "        results = result.fetchall()\n",
    "\n",
    "        if results:\n",
    "            for row in results:\n",
    "                connection.execute(\n",
    "                    text(insert_query),\n",
    "                    {\n",
    "                        \"host_id\": row[0],\n",
    "                        \"host_name\": row[1],\n",
    "                        \"host_location\": row[2],\n",
    "                        \"average_price\": row[3],\n",
    "                        \"total_listings\": row[4],\n",
    "                    }\n",
    "                )\n",
    "            print(f\"{len(results)} records inserted into RESULTS.\")\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"{len(results)} results found and inserted in {end_time - start_time:.4f} seconds\")\n",
    "        else:\n",
    "            print(\"No results to insert.\")\n",
    "\n",
    "\n",
    "        print(\"\\nRemoving created indexes\")\n",
    "        connection.execute(text(\"DROP INDEX idx_listings_host_id ON LISTINGS;\"))\n",
    "        connection.execute(text(\"DROP INDEX idx_host_statistics_host_id ON HOST_STATISTICS;\"))\n",
    "        connection.execute(text(\"DROP INDEX idx_host_location ON HOST;\"))\n",
    "        connection.execute(text(\"DROP INDEX idx_listings_availability_price ON LISTINGS;\"))\n",
    "        connection.execute(text(\"DROP INDEX idx_host_statistics_listings_count ON HOST_STATISTICS;\"))\n",
    "        print(\"Indexes removed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while creating the indexes or executing the query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize insert in RESULTS table\n",
    "\n",
    "username = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database_name = 'Project_DB'\n",
    "\n",
    "db_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        query_all = text(\"SELECT * FROM RESULTS\")\n",
    "        result_all = connection.execute(query_all)\n",
    "        rows = result_all.fetchall()\n",
    "        \n",
    "        print(\"Contents of the RESULTS table:\")\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "        \n",
    "        query_count = text(\"SELECT COUNT(*) FROM RESULTS;\")\n",
    "        result_count = connection.execute(query_count)\n",
    "        count = result_count.scalar()  # single value result\n",
    "        \n",
    "        print(f\"The RESULTS table contains {count} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear RESULTS table\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        query_clear = text(\"DELETE FROM RESULTS\")\n",
    "        result_clear = connection.execute(query_clear)\n",
    "    \n",
    "        connection.commit()    \n",
    "        print(f\"All rows deleted from the RESULTS table. Total rows affected: {result_clear.rowcount}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while clearing the RESULTS table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complex query 2: Atualização de preços de Listings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base_price_update_query = \"\"\"WITH high_reviewed_listings AS (\n",
    "    SELECT \n",
    "        l.id AS listing_id\n",
    "    FROM LISTINGS l\n",
    "    WHERE l.review_scores_rating > 4.5\n",
    "      AND l.number_of_reviews > 100\n",
    "),\n",
    "active_hosts AS (\n",
    "    SELECT \n",
    "        h.id AS host_id,\n",
    "        MAX(hs.total_listings_count) AS max_listings_count,\n",
    "        SUM(l.has_availability) AS available_listings\n",
    "    FROM HOST h\n",
    "    JOIN HOST_STATISTICS hs ON h.id = hs.host_id\n",
    "    JOIN LISTINGS l ON h.id = l.host_id\n",
    "    WHERE h.location = 'Albany, NY'\n",
    "    GROUP BY h.id\n",
    ")\n",
    "UPDATE LISTINGS l\n",
    "JOIN high_reviewed_listings hl ON l.id = hl.listing_id\n",
    "JOIN active_hosts ah ON l.host_id = ah.host_id\n",
    "SET l.base_price = l.base_price * 1.1\n",
    "WHERE ah.max_listings_count > 5\n",
    "  AND ah.available_listings > 3\n",
    "  AND l.base_price < 300;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 results changed in 0.0502 seconds\n"
     ]
    }
   ],
   "source": [
    "# without index\n",
    "\n",
    "username = 'root'\n",
    "password = 'password'\n",
    "# password = '1234' \n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database_name = 'Project_DB'\n",
    "\n",
    "db_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        start_time = time.time()\n",
    "        result = connection.execute(text(new_base_price_update_query))\n",
    "        connection.commit()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        affected_rows = result.rowcount\n",
    "        print(f\"{affected_rows} results changed in {end_time - start_time:.4f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while executing the query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing indexes:\n",
      "No indexes in LISTINGS\n",
      "\n",
      "Creating indexes...\n",
      "Indexes created successfully.\n",
      "\n",
      "Executing the query...\n",
      "20 results changed in 0.0168 seconds\n",
      "\n",
      "Removing created indexes...\n",
      "Indexes removed successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Existing indexes:\")\n",
    "        listings_indexes = connection.execute(text(\"SHOW INDEX FROM LISTINGS\"))\n",
    "\n",
    "        if listings_indexes.rowcount > 0:\n",
    "            print(\"\\nIndexes in LISTINGS:\")\n",
    "            for row in listings_indexes:\n",
    "                print(row)\n",
    "        else:\n",
    "            print(\"No indexes in LISTINGS\")\n",
    "\n",
    "        # add indexes\n",
    "        print(\"\\nCreating indexes...\")\n",
    "        connection.execute(text(\"CREATE INDEX id_index ON LISTINGS (id);\"))\n",
    "        connection.execute(text(\"CREATE INDEX list_index ON LISTINGS (base_price, has_availability);\"))\n",
    "        connection.execute(text(\"CREATE INDEX review_scores_index ON LISTINGS (review_scores_rating, number_of_reviews);\"))\n",
    "        print(\"Indexes created successfully.\")\n",
    "\n",
    "        print(\"\\nExecuting the query...\")\n",
    "        start_time = time.time()\n",
    "        result = connection.execute(text(new_base_price_update_query))\n",
    "        connection.commit()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        affected_rows = result.rowcount\n",
    "        print(f\"{affected_rows} results changed in {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "        # remove indexes\n",
    "        print(\"\\nRemoving created indexes...\")\n",
    "        connection.execute(text(\"DROP INDEX id_index ON LISTINGS;\"))\n",
    "        connection.execute(text(\"DROP INDEX list_index ON LISTINGS;\"))\n",
    "        connection.execute(text(\"DROP INDEX review_scores_index ON LISTINGS;\"))\n",
    "        print(\"Indexes removed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
